云游戏传输调度优化

多个环境
笔记本目录MM2021下的是修改过QoE计算模型的代码
流媒体服务器上的环境：跑实验时修改了多个优先级下的QoE计算
台式上的是修改过block的

核心是1.deadline可变感知，2.调度与拥塞控制结合决策
实验设计：
级联模型在仿真器中进行训练，其实这个较为简单，麻烦的以真实平台进行实验
跨了应用层与传输层，其实是属于在应用层收集的数据，但是需要部署到网络层中

10.16问题：

还要加入vmaf，是否会使得简单调度变得过于复杂，从而使得效率反而变低，可以考虑干脆去除这一块

收集数据集(改网卡玩游戏)

改QoE模型(按不同用户计算，具体公式？主要是收集到的是每一帧的大小和时间戳)

deadline感知，如何感知？（在最小容忍度和最大容忍度之间滑动，）

感知完了之后送入模型训练，模型怎么写？

训练完成之后部署到平台上，如何部署？



10.23问题:

数据集问题：

1.收集到的是帧而不是块，也用仿真器吗？

2.需要限制网卡吗？反正数据大小是固定的(影响到时间戳)

3.帧数据真的有用吗？会显著提高复杂度，得不偿失

deadline可变感知问题：

先把模型搭出来然后再做实验，基于控制信令密集程度来对deadline在0和最大容忍度之间滑动

平台问题：
最多只允许两个人进行游戏，但因为可以使用VM，所以数据集的收集没啥问题，但是真实部署的时候就存在问题，每一个session是单独调度，所以是多端口，因此如果平台主人可以修改加入index3和4，那么还是单端口，否则就需要加入多链路变成多端口，但是多端口是在竞争什么呢？（网络中总资源有限，所以多端口的话相互于是这个服务器自觉地让出自己的一部分资源，减少发送速率，但是跟调度就没什么关联了）

模型问题：
模型(改deadline可变为优先级设置？)
根据规则设定用户优先级
DRL输入为网络情况，奖励设置时加入优先级奖励

**（人为定义eposide，多少帧一个block）
（QoE：vmaf修改为间隔性采，降低复杂度，最后考虑延迟，视频质量，卡顿）
（关于模型的问题：deadline，学习模型，最后是级联模型）deadline基于控制信令作一个学习，输出一个值，然后视频音频再进行放缩。(informer去学习deadline)
1.VMAF改进，CAMBI，先试试vmaf部署情况下**
2.造一下数据跑一下看看效果如何 效果还行

10.25问题：

数据预处理问题：
设置一个episode，每隔一个episode处理一次，所以需要考虑时间同步，以秒为单位好一些，控制信令与视频数据与音频数据如何进行同步

10.26：
deadline：
1.ITU-T,Y.IMT2020-qos-req-cg,但是处于under study状态，还无法使用，这个可以得到关于云游戏的延迟qos参数
2.13年IEEE Network论文，关于各种游戏的latency threshold，再加上18TCSVT的那一篇delay模型，自己大概估计一个？
3.domain expert
4.DetNet的end-end delay model计算。
5.ACM MM的图

10.29
目前难点：
1.deadline感知？
2.如何将最终模型与平台相结合？（部署问题：其实这是一个跨层优化问题，内容感知肯定是发生在应用层，决策是在网络层，目前问题在于，既然在网络层决策，那么数据收集是否应该在网络层收集，数据收集代码是在应用层收集的，到时候部署在真实的平台中可能会发生问题） 无法进行结合，只能进行仿真。

